{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "from pycocotools.coco import COCO\n",
    "site = 'val'\n",
    "img_dir = f'./data/jinan/pan/{site}/JPEGImages'\n",
    "json_path = f'./data/jinan/fusion/{site}/{site}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.41s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco = COCO(json_path)\n",
    "img_ids = set(_['image_id'] for _ in coco.anns.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.datasets.pipelines import Compose\n",
    "from mmcv.parallel import collate, scatter\n",
    "from mmdet.datasets import replace_ImageToTensor\n",
    "def inference_detector(model, imgs):\n",
    "    \"\"\"Inference image(s) with the detector.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The loaded detector.\n",
    "        imgs (str/ndarray or list[str/ndarray] or tuple[str/ndarray]):\n",
    "           Either image files or loaded images.\n",
    "\n",
    "    Returns:\n",
    "        If imgs is a list or tuple, the same length list type results\n",
    "        will be returned, otherwise return the detection results directly.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(imgs, (list, tuple)):\n",
    "        is_batch = True\n",
    "    else:\n",
    "        imgs = [imgs]\n",
    "        is_batch = False\n",
    "\n",
    "    cfg = model.cfg\n",
    "    device = next(model.parameters()).device  # model device\n",
    "\n",
    "    if isinstance(imgs[0], np.ndarray):\n",
    "        cfg = cfg.copy()\n",
    "        # set loading pipeline type\n",
    "        cfg.data.test.pipeline[0].type = 'LoadImageFromWebcam'\n",
    "\n",
    "    cfg.data.test.pipeline = replace_ImageToTensor(cfg.data.test.pipeline)\n",
    "    test_pipeline = Compose(cfg.data.test.pipeline)\n",
    "\n",
    "    datas = []\n",
    "    for img in imgs:\n",
    "        # prepare data\n",
    "        if isinstance(img, np.ndarray):\n",
    "            # directly add img\n",
    "            data = dict(img=img)\n",
    "        else:\n",
    "            # add information into dict\n",
    "            data = dict(img_info=dict(filename=img), img_prefix=None)\n",
    "        # build the data pipeline\n",
    "        data = test_pipeline(data)\n",
    "        datas.append(data)\n",
    "\n",
    "    data = collate(datas, samples_per_gpu=len(imgs))\n",
    "    # just get the actual data from DataContainer\n",
    "    data['img_metas'] = [img_metas.data[0] for img_metas in data['img_metas']]\n",
    "    data['img'] = [img.data[0] for img in data['img']]\n",
    "    if next(model.parameters()).is_cuda:\n",
    "        # scatter to specified GPU\n",
    "        data = scatter(data, [device])[0]\n",
    "    else:\n",
    "        for m in model.modules():\n",
    "            assert not isinstance(\n",
    "                m, RoIPool\n",
    "            ), 'CPU inference with RoIPool is not supported currently.'\n",
    "\n",
    "    # forward the model\n",
    "    with torch.no_grad():\n",
    "        results = model(return_loss=False, rescale=True, **data)\n",
    "\n",
    "    if not is_batch:\n",
    "        return results[0]\n",
    "    else:\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import init_detector, show_result_pyplot\n",
    "import mmcv\n",
    "import glob\n",
    "work_dir = './venus_last_tf/15'\n",
    "config_file = glob.glob(os.path.join(work_dir, '*.py'))[0]\n",
    "checkpoint_file = os.path.join(work_dir, 'latest.pth')\n",
    "cfg_options = {}\n",
    "cfg_options = {'model.roi_head.polygon_head.polyrnn_head.weight_kernel_params.kernel_size': 3, \n",
    "               'model.roi_head.polygon_head.polyrnn_head.weight_kernel_params.type': 'gaussian'}\n",
    "\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0', cfg_options=cfg_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mmcv\n",
    "import cv2\n",
    "import torch\n",
    "import tifffile as tiff\n",
    "def show_result(img_path, result, score_thr):\n",
    "    img = tiff.imread(img_path)\n",
    "    img = img[:, :, :3][:, :, ::-1]\n",
    "    img = img.copy()\n",
    "    bbox_result, segm_result = result\n",
    "    bboxes = np.vstack(bbox_result)\n",
    "    labels = [\n",
    "        np.full(bbox.shape[0], i, dtype=np.int32)\n",
    "        for i, bbox in enumerate(bbox_result)\n",
    "    ]\n",
    "    labels = np.concatenate(labels)\n",
    "    # draw segmentation masks\n",
    "    segms = None\n",
    "    if segm_result is not None and len(labels) > 0:  # non empty\n",
    "        segms = mmcv.concat_list(segm_result)\n",
    "        if isinstance(segms[0], torch.Tensor):\n",
    "            segms = torch.stack(segms, dim=0).detach().cpu().numpy()\n",
    "        else:\n",
    "            segms = np.stack(segms, axis=0)\n",
    "    scores = bboxes[:, -1]\n",
    "    inds = scores > score_thr\n",
    "    bboxes = bboxes[inds, :]\n",
    "    labels = labels[inds]\n",
    "    if segms is not None:\n",
    "        segms = segms[inds, ...]\n",
    "    for i, (bbox, label) in enumerate(zip(bboxes, labels)):\n",
    "        mask = segms[i].astype(np.uint8)\n",
    "        contours, hierarchy = cv2.findContours(mask[..., None], cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cv2.drawContours(img, contours, -1, (0,0,255), 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799\n"
     ]
    }
   ],
   "source": [
    "print(len(img_ids))\n",
    "output_dir = './polyrnn_visual_jinan'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 784/799 [1:08:03<01:29,  5.98s/it]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "img_ids = list(img_ids)\n",
    "\n",
    "for bi, img_id in enumerate(tqdm(img_ids)):\n",
    "    fn = coco.load_imgs([img_id])[0]['file_name']\n",
    "    img_path = os.path.join(img_dir, fn)\n",
    "    \n",
    "    result = inference_detector(model, img_path)\n",
    "#     show_result_pyplot(model, img_path, result, score_thr=0.2)\n",
    "    img_path = img_path.replace('pan', 'fusion')\n",
    "    img = show_result(img_path, result, score_thr=0.6)\n",
    "#     img = img[:, :, ::-1]\n",
    "#     plt.figure(figsize=(15, 10))\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    out_path = os.path.join(output_dir, fn)\n",
    "    out_path = out_path.replace('.tif', '.png')\n",
    "    cv2.imwrite(out_path, img)\n",
    "#     if bi > 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_roczhou_mmd)",
   "language": "python",
   "name": "conda_roczhou_mmd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
