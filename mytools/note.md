## 数据划分
- 切片大小：512
- 重叠：64
- 训练和测试数据：7:3
- 随机数种子1234

## 实验
比较模型：mask rcnn和panet

**对每一个实验，记录配置文件和地址，以及结果，随机数种子默认为1234**

baseline 进行不同的实验设置，具体挑选可后续选择

1. padding位置信息和non-local模块
2. 损失平滑(点的预测和多边形的预测)
3. attention结构
4. offset偏移分支
5. 训练流程和测试流程不一致
6. 解决显存问题
7. 特征融合（vertex,edge,mask）
    1. 仅提供损失
    2. concat
    3. 类似Bmask, 特征融合
8. 利用点的预测结果得分对最后结果进行调整

**对比实验**
- venus/0 faster rnn 4gpu, 0.01学习率，resnet50，12epoch
- venus/1 mask rcnn 同上
- venus/2 ms rnn 同上

**polyrnn**
由于使用lstm以及代码不完善，会OOM，限定每个GPU一个sample
暂定默认配置
1. 0.005, 4gpu, 24epoch
2. 未使用attention
3. 28
4. 最长序列20
5. 其他参数后续补充

- venus/3 0315
    - 从结果上看，前期epoch并不好，可能是损失比较苛刻，以及训练和测试流程不一致的问题
- venus/4 0315_1 使用attention
    - 根据实验结果，目前使用的attention结构并不好，需要修改
- venus/5 0315_2 最长序列使用30
- venus/6 0316 attention结构 + x, attention_type=2
- venus/7 0315_1 重做实验4
- venus/8 0316_2 多边形尺度为14
- venus/9 原本测试attention_type=3,疯狂nan，暂时放弃，改利用更多的epoch
- venus/10 polygon_loss权重为0.1
- venus/11 polygon_loss权重为0.5
- venus/12 位置信息加载polyrnn_head头部分
- venus/13 mask分支，仅利用mask损失
- venus/14 use_bn=True,lr=0.001
- venus/15 使用更小的池化大小，vertex_head通过上采样训练，结果很差，从损伤看仍然较大
- venus/16 0318_1 polygon_scale_factor=1.0 基本和3一样，不过多了边界去截断
- venus/17 0318_2 use_coord and coord_type=2
- venus/18 0318_3 时序为10
- venus/19 0318_4 polygon_scale_factor=1.1
- venus/20 0319 polygon_scale_factor=1.2
- venus/21 0319_1 refine_level=2, 16
- venus/22 0319_2 refine_level=1, non_local
- venus/23 0319_3 refine_level=0, 4
- venus/24 0321 空洞卷积 [2, 4, 6, 8], BN
- venus/25 0321_1 nonlocal 后使用上述模块
- venus/26 0321_2 polygon_scale_factor=1.05



**表格结果（仅列出最后一个epoch）**

work_dir | map | ap@50 | ap@75 | ap@small | ap@medium | ap@large
- | - | - | - | - | - | - 
0 | 40.4/- | 61.6/- | 45.2/- | 25.2/- | 48.5/- | 50.5/-
1 | 40.7/38.4 | 62.0/60.8 | 45.3/43.3 | 25.8/24.3 | 49.0/47.1 | 49.5/44.2
2 | 41.1/39.4 | 62.6/61.8 | 45.9/44.1 | 26.8/27.3 | 48.6/46.7 | 49.4/42.7
3 | 39.4/32.8 | 61.5/57.7 | 43.3/35.2 | 28.9/24.8 | 46.6/40.8 | 44.8/30.0
4 | 39.3/30.7 | 61.0/55.1 | 43.0/31.9 | 29.0/23.2 | 47.0/39.3 | 44.8/27.3
5 | 38.5/32.2 | 59.9/56.1 | 42.6/34.5 | 28.9/24.2 | 45.9/39.6 | 37.6/27.0
6 | 39.5/32.8 | 60.9/57.1 | 43.7/35.4 | 29.7/25.3 | 46.8/40.9 | 44.1/29.3
7 | 39.9/31.1 | 61.7/56.1 | 44.0/32.4 | 28.6/23.4 | 47.5/39.5 | 46.7/27.5
8 | 40.5/29.8 | 62.4/58.7 | 44.5/28.8 | 29.4/25.1 | 47.6/36.8 | 46.9/25.1
9 | 38.5/32.9 | 60.0/57.0 | 41.8/35.5 | 27.6/24.0 | 45.3/40.6 | 43.5/30.7
10 | 39.9/27.3 | 59.9/50.3 | 44.2/28.4 | 25.5/17.7 | 47.0/35.2 | 47.8/23.6
11 | 40.6/32.6 | 62.4/57.4 | 44.3/34.9 | 29.7/24.7 | 47.9/40.8 | 46.1/26.2
12 | 39.6/33.5 | 61.7/58.0 | 43.7/36.1 | 29.4/25.0 | 46.4/41.1 | 45.7/32.3
13 | 39.2/32.8 | 61.0/57.4 | 43.3/35.1 | 29.2/24.8 | 46.0/40.2 | 44.3/31.2
14 | 38.6/31.3 | 61.0/56.2 | 42.2/32.7 | 28.4/22.4 | 46.3/39.7 | 42.3/29.2
15 | 39.6/11.0 | 61.8/24.4 | 43.7/10.3 | 28.9/12.2 | 46.9/13.7 | 43.9/7.5
16 | 39.4/33.0 | 61.4/57.7 | 43.3/35.4 | 29.4/25.0 | 46.3/40.8 | 44.6/30.7
17 | 39.6/33.1 | 61.7/57.4 | 43.8/35.7 | 29.4/24.8 | 46.9/41.3 | 44.3/30.2
18 | 39.7/31.2 | 61.4/55.1 | 43.8/32.9 | 29.3/24.9 | 46.8/40.2 | 44.9/22.3
19 | 39.3/33.0 | 61.4/57.4 | 43.0/35.3 | 29.2/25.2 | 46.2/40.8 | 44.8/31.0
20 | 39.1/32.4 | 61.1/56.5 | 43.2/35.1 | 29.1/24.7 | 46.3/40.4 | 43.9/29.4
21 | 39.2/31.7 | 61.2/53.9 | 43.1/32.9 | 29.4/22.8 | 46.9/39.9 | 41.9/29.5
22 | 39.9/33.0 | 62.0/57.9 | 43.9/34.4 | 29.6/24.5 | 46.9/41.1 | 45.4/29.5
23 | 39.2/33.1 | 61.6/57.9 | 42.8/35.4 | 28.6/24.9 | 46.4/41.0 | 44.7/31.2
24 | 39.4/31.3 | 61.5/56.1 | 43.3/33.0 | 29.7/23.7 | 46.6/39.6 | 45.5/28.6
25 | 39.5/31.8 | 61.8/57.0 | 43.5/33.0 | 29.7/24.0 | 46.6/39.8 | 45.0/28.5
26 | 39.9/32.8 | 61.9/57.1 | 43.9/35.2 | 29.7/25.1 | 47.2/40.8 | 45.1/30.3


**分析**
1. ms rcnn在小物体提升明显，小物体上更好的感受野以及一种监督损失？
2. 实验3表示分割精度和检测精度相差较大，特别是大物体，或许需要更好的感受野？ap@75相比于ap@50,检测和分割精度相差更大，也就是更精细的定位上有问题
3. 实验4基于attention的效果并大好，甚至有所下降（attetion处代码有问题），可以放弃
5. 实验5增加序列长度，并没有获得更好的效果，很奇怪，从损失上看，比实验3较大，后期效果基本稳定，也许存在权重影响
6. 从实验7对比实验4来看，会稍微更好些，但是差别不大
7. 实验8用了更小的尺度，但是检测精度高了，而分镜精度主要影响大尺度物体，小尺度物体甚至有提升，损失权重需要调整，对比实验3
8. 实验16和实验19，scale_factor影响结果不大


**代码日志**
1. 0316
    修改attention部分代码，增加参数attention_type，默认参数为1，另外参数2,3，对应不同的结构，暂时调参使用
    原始attention错误，relu激活之后，采用softmax，性能差是否有这方面的影响，需要重新做实验4
    注释 attention_type == 3时，疯狂nan
2. 0317
    小修改，原始配置文件，加入损失参数，不会影响实验
    添加坐标信息，在第一次的PolyRnnHead卷积处
3. 0318
    增加缩放尺度，应该不会很影响，建议测试（不确定之前是否截断图片尺度）,通过原始值为None，来确保和之前一样
    attention修改， attention_type=5, 仅在1的基础上使用sigmoid
    坐标信息，在lstm前每个都进行，coord_type=2
    polygon_size 不再限制(需要缩放vertex_head，对结果可能并不好)，此处是否可以先池化，后升维再做，显存瓶颈在lstm处

**参数调整**
注意：实验结果从上面表格获取，此处作为总结

测试Polyon_size影响，后续可能会改代码流程

work_dir | polygon_size |map | ap@50 | ap@75 | ap@small | ap@medium | ap@large
- | - | - | - | - | - | - | - 
3 | 28 | 39.4/32.8 | 61.5/57.7 | 43.3/35.2 | 28.9/24.8 | 46.6/40.8 | 44.8/30.0
8 | 14 | 40.5/29.8 | 62.4/58.7 | 44.5/28.8 | 29.4/25.1 | 47.6/36.8 | 46.9/25.1

测试时序长度
work_dir | polygon_size |map | ap@50 | ap@75 | ap@small | ap@medium | ap@large
- | - | - | - | - | - | - | - 
3 | 20 | 39.4/32.8 | 61.5/57.7 | 43.3/35.2 | 28.9/24.8 | 46.6/40.8 | 44.8/30.0
5 | 30 | 38.5/32.2 | 59.9/56.1 | 42.6/34.5 | 28.9/24.2 | 45.9/39.6 | 37.6/27.0


**需要做的实验**
1. nonlocal + attention
2. 位置卷积 暂时有0.7的收益
3. 时序长度为10的测试
4. poly_size代码流程，需要思考可行否
